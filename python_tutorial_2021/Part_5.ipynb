{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AST 376R - Introduction to Python Part 5\n",
    "## by Jonathan Florez\n",
    "\n",
    "# Pandas, Statistical Functions, and Array Sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas\n",
    "\n",
    "Pandas is a Python data analysis library that consists of a powerful set of tools capable of reading and writing data in different formats (e.g., CSV, txt, Excel, SQL, HDF5), handling data alignment and missing values intelligently, reshaping data sets, merging and joining data sets, etc. Pandas is used in a large number of academic and commercial domains due its flexibility and efficiency in handling large array and data set operations. Although it is not necessarily used to perform statistical functions in Python, it is often used in conjunction with machine learning and advanced statistics algorithms. In the examples below, notice how the usage of Pandas functions vary from functions like those in Numpy. \n",
    "\n",
    "### Reading files with Pandas\n",
    "In this tutorial, we will read in a CSV file named sample_catalog.csv. Each column in this file has a name, so Pandas will automatically assign the corresponding column the correct name based on what is in the file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('sample_catalog.csv') ## Reads a csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, 'df' is what is known as a Pandas DataFrame. A DataFrame is a 2-dimensional labeled data structure with columns of (potentially) different variable types. This can be somewhat visualized as a stored spreadsheet within Pandas.\n",
    "\n",
    "The usage is similar for other data types. If you have a .txt file, instead of csv, you can read the file using: pd.read_table('file_name.txt').\n",
    "Now that we have read in our file into a DataFrame, let's look at what is inside the DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head() ## Nicely shows the first 5 rows of each column\n",
    "## Note that df.head(n) shows first n rows of each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail() ## Shows the last 5 rows of each column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the DataFrame looks like a nicely formatted table with strings, floats, and integers. We did not even have to specify what each variable type is. You can look at the column names with the DataFrame.columns function.\n",
    "\n",
    "Let's look at the individual column names in this data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cols in df.columns:\n",
    "    print(cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at each variable data type in this DataFrame by calling DataFrame.dtypes (e.g., df.dtypes[0] would show the data type of the first variable in the df DataFrame). \n",
    "### Question 1:\n",
    "Make a for loop, similar to the one above, that prints out the column name and data type of each variable inside the df DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Solution below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, strings are referred to as 'object', whereas 64-bit floats and integers are referred to as 'float64' and 'int64', respectively.\n",
    "\n",
    "IF your file does not provide column names, then you will have to assign those on your own. To do this, you simply create an array of strings and supply those to pd.read_table() or pd.read_csv(). Say you are reading a table in with three columns and no column names. You can assign a column each name and read your file by doing the following:\n",
    "\n",
    "cols = ['x', 'y', 'z']\\\n",
    "df = pd.read_table('file_name.txt',names=cols)\n",
    "\n",
    "Now, df['x'] will call the 'x' variable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing Files in Pandas\n",
    "\n",
    "Saving a DataFrame to Pandas in incredibly easy. We can define our own DataFrame, by creating a Python dictionary, and save that to a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save a subset of df to a csv file:\n",
    "\n",
    "sub_dict = {'Name': df['NAME'], 'RADEG': df['RADEG'], 'DEDEG': df['DEDEG'], 'CZ': df['CZ']}\n",
    "\n",
    "# sub_dict is now a dictionary. The name of the variable is supplied in the strings, the variable is supplied\n",
    "# after the colon. Dictonaries are always defined within curly brackets\n",
    "\n",
    "dfout = pd.DataFrame(sub_dict) ## Define a new DataFrame based on Python Dictionary\n",
    "\n",
    "dfout.to_csv('sample_out.csv',index_label='Index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "more sample_out.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Functions in Numpy\n",
    "\n",
    "Numpy has a large number of functions built for efficiently performing basic statistical operations on arrays. A few useful ones are listed below:\n",
    "\n",
    "np.mean()\\\n",
    "np.average() - Similar to np.mean, but accepts weights\\\n",
    "np.median()\\\n",
    "np.max()\\\n",
    "np.min()\\\n",
    "np.percentile() - returns the nth percentile value of a distribution\n",
    "\n",
    "Let's look at some examples using the data we loaded with Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate the mean, minimum and maximum LOGMSTAR values from our data set.\n",
    "\n",
    "LOGMSTAR = df['LOGMSTAR']\n",
    "print(\"mean:\", np.mean(LOGMSTAR), \"minimum:\", np.min(LOGMSTAR), \"maximum:\", np.max(LOGMSTAR))\n",
    "\n",
    "\n",
    "# Now let's say we want to assign weights to our values and calculate\n",
    "# the weighted average. A weight in statistical terms is defined\n",
    "# as a coefficient assigned to a number in a computation, for example when \n",
    "# determining an average, to make the number's effect on \n",
    "# the computation reflect its importance\n",
    "\n",
    "weights = df['CCR'] ## 'CCR' are the weight coefficients for this data set\n",
    "\n",
    "print(\"weighted average:\",np.average(LOGMSTAR,weights=weights))\n",
    "\n",
    "## Let's compute the 5th and 95th percentile values of the LOGMSTAR distribution\n",
    "\n",
    "print(\"5th percentile:\", np.percentile(LOGMSTAR, 5), \"95th percentile:\", np.percentile(LOGMSTAR, 95))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "Plot a histogram of the variable in the df DataFrame with the name 'LOGMGAS'. On this histogram, plot the 16th and 84th percentile values as vertical dashed lines. Also plot the weighted average as a solid line. Label the x-axis as: $\\log(M_{\\rm gas}/M_{\\odot})$.\n",
    "\n",
    "You may want to set the limits of the y-axis with the command plt.ylim(top, bottom)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Solution below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Array Sorting\n",
    "\n",
    "We will now look at how to sort arrays in Python. This will allow you to order arrays by their numerical value in ascending or descending order.\n",
    "\n",
    "This is a relatively straightforward thing to do in Python. You can sort an array with the following command in Numpy:\n",
    "\n",
    "sorted_array = np.sort(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example of np.sort()\n",
    "\n",
    "rmag = df['ABSRMAG'] # load r-band magnitudes from df \n",
    "\n",
    "rmag_sorted = np.sort(rmag)\n",
    "\n",
    "for r in rmag_sorted:\n",
    "    print(r)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more useful function than np.sort is the np.argsort() function which returns the indices of the sorted array, rather than the sorted array itself. This essentially allows you to sort an entire table or 2-dimensional array based on the numerical values of one variable. Note that you will have to do this for HW 4!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example of np.argsort()\n",
    "\n",
    "sort_ind = np.argsort(rmag) #returns the indices of the rmag array once sorted. \n",
    "\n",
    "## Above, we got rmag_sorted by defining it as: 'rmag_sorted = np.sort(rmag)'\n",
    "## We can get the same array with argsort:\n",
    "\n",
    "new_rmag_sorted = rmag[sort_ind]\n",
    "\n",
    "for r in new_rmag_sorted:\n",
    "    print(r)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "The 'CZ' parameter in this catalog is a recessional velocity. It is calculated as the speed of light times redshift (c*z). The larger an object's recessional velocity is, the further away that object is. For this problem, sort the values of 'NAME', 'RADEG', 'DEDEG', 'CZ', and 'LOGMSTAR' by recessional velocity such that object closest to us is the first object in each array, and the object furthest from us is the last object in each array.\n",
    "\n",
    "Create a dictionary with these sorted values, convert that dictionary into a DataFrame, and write that out to a CSV file named 'Q3_out.csv'. This file will have the columns 'NAME', 'RADEG', 'DEDEG', 'CZ', and 'LOGMSTAR.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Solution below"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
